<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>HDFS on YanHowey Wang</title><link>https://howey.deno.dev/tags/hdfs/</link><description>Recent content in HDFS on YanHowey Wang</description><generator>Hugo -- gohugo.io</generator><language>en</language><lastBuildDate>Wed, 26 Jul 2023 22:21:16 +0800</lastBuildDate><atom:link href="https://howey.deno.dev/tags/hdfs/index.xml" rel="self" type="application/rss+xml"/><item><title>HDFS介绍以及shell操作</title><link>https://howey.deno.dev/posts/hdfs%E4%BB%8B%E7%BB%8D%E4%BB%A5%E5%8F%8Ashell%E6%93%8D%E4%BD%9C/</link><pubDate>Wed, 26 Jul 2023 22:21:16 +0800</pubDate><guid>https://howey.deno.dev/posts/hdfs%E4%BB%8B%E7%BB%8D%E4%BB%A5%E5%8F%8Ashell%E6%93%8D%E4%BD%9C/</guid><description>HDFS Link to heading @[TOC]
一、HDFS 定义 Link to heading HDFS 即（hadoop distributed file system），采用目录树来定位文件；其次，它是分布式的，由很多服务器联合起来实现其功能，集群中的服务器有各自的角色 HDFS 的使用场景：适合一次写入，多次读出的场景
二、HDFS 优缺点： Link to heading 1.优点： Link to heading 高容错性 数据自动保存多个副本。通过增加副本的形式，提高容错性 某一个副本丢失以后，可以自动回复 适合处理大数据 数据规模大的（甚至 PB），文件规模大的（上百万） 可以构建在廉价机器上，通过多副本机制，提高可靠性 2.缺点： Link to heading 不适合低延时数据访问，比如毫秒级存储 无法高效的对大量小文件进行存储（1.存储大量小文件，会占用 nameNode 大量的内存用来存储文件目录和块消息，namenode 内存总是有限的 2.小文件存储的寻址时间会超过读取时间，违反了 hdfs 的设计目的） 不支持并发写入，文件的随机修改，（1.一个文件只能有一个写，不允许多个线程同时写 2.仅支持数据的追加，不支持修改） 三、HDFS 组织架构 Link to heading client: 分别访问 NameNode 和 DataNode 以获取文件的元信息及内容。
SecondaryNamenode：辅助 namenode 用于定期合并 fsimage 和 edits，生成新的 fsimage，并推送给 Namenode，在紧急情况下 可用于恢复 namenode 部分数据</description></item><item><title>HDFS常用API操作</title><link>https://howey.deno.dev/posts/hdfs%E5%B8%B8%E7%94%A8api%E6%93%8D%E4%BD%9C/</link><pubDate>Wed, 26 Jul 2023 22:21:16 +0800</pubDate><guid>https://howey.deno.dev/posts/hdfs%E5%B8%B8%E7%94%A8api%E6%93%8D%E4%BD%9C/</guid><description>1.下载 winutils.exe Link to heading https://codeload.github.com/tangchunbo/apache-hadoop-3.1.1-winutils/zip/refs/heads/master 然后解压将文件拷贝到 bin 目录下 D:\Java\hadoop-3.3.1\bin 依赖导入
&amp;lt;dependencies&amp;gt; &amp;lt;dependency&amp;gt; &amp;lt;groupId&amp;gt;org.apache.hadoop&amp;lt;/groupId&amp;gt; &amp;lt;artifactId&amp;gt;hadoop-client&amp;lt;/artifactId&amp;gt; &amp;lt;version&amp;gt;3.1.3&amp;lt;/version&amp;gt; &amp;lt;/dependency&amp;gt; &amp;lt;dependency&amp;gt; &amp;lt;groupId&amp;gt;junit&amp;lt;/groupId&amp;gt; &amp;lt;artifactId&amp;gt;junit&amp;lt;/artifactId&amp;gt; &amp;lt;version&amp;gt;4.12&amp;lt;/version&amp;gt; &amp;lt;/dependency&amp;gt; &amp;lt;dependency&amp;gt; &amp;lt;groupId&amp;gt;org.slf4j&amp;lt;/groupId&amp;gt; &amp;lt;artifactId&amp;gt;slf4j-log4j12&amp;lt;/artifactId&amp;gt; &amp;lt;version&amp;gt;1.7.30&amp;lt;/version&amp;gt; &amp;lt;/dependency&amp;gt; &amp;lt;/dependencies&amp;gt; package com.howey.hdfs; import org.apache.hadoop.conf.Configuration; import org.apache.hadoop.fs.*; import org.junit.After; import org.junit.Before; import org.junit.Test; import java.io.IOException; import java.net.URI; import java.net.URISyntaxException; import java.util.Arrays; /** * 1.获取客户端对象 * 2.执行相关的操作命令 * 3.关闭资源 */ public class HdfsClient { private FileSystem fs; @Before public void init() throws URISyntaxException, IOException, InterruptedException { URI uri = new URI(&amp;#34;hdfs://hadoop102:8020&amp;#34;); //创建一个配置文件 Configuration entries = new Configuration(); //设置副本 entries.</description></item><item><title>HDFS读写数据流程</title><link>https://howey.deno.dev/posts/hdfs%E8%AF%BB%E5%86%99%E6%95%B0%E6%8D%AE%E6%B5%81%E7%A8%8B/</link><pubDate>Wed, 26 Jul 2023 22:21:16 +0800</pubDate><guid>https://howey.deno.dev/posts/hdfs%E8%AF%BB%E5%86%99%E6%95%B0%E6%8D%AE%E6%B5%81%E7%A8%8B/</guid><description>HDFS 读写数据流程 Link to heading @[TOC]
一、HDFS 写数据流程 Link to heading 客户端发起请求上传文件 namenode 检查目录树是否可以创建文件（1.检查权限，2 检查目录树结构，目录是否存在）并响应客户端是否可上传 客户端对文件进行分操作形成 block 块 请求上传第一个 block，请求返回 datanode（上传的数据真实存储的地址） 根据机架感应原理，网络拓扑关系，副本机制，找到相应可以上传的 datanode 连接列表，返回给客户端。 根据返回的连接列表 客户端请求与第一台机器建立 block 传输通道 datanode 连接列表一次进行连接形成一条完整的 pipeline 管道 客户端，将第一个数据包 packet（64k 由（chunk512b+chunksum4b）组成）发送数据，然后依次由服务器进行管道传输，服务器会自我保存一份 第一个请求完成之后，建立一条反向应答通道，ack 应答机制 10.第一个请求完成之后，开始继续发送 packet，当第一个 block 发送完成后，此时 client 重新向 namenode 发送请求，获取第二个 block 应该存储到哪个 datanode 中，接着开始从第 5 步不断执行，直到所有的 block 完全写入。 二、节点距离计算 Link to heading 到达共同祖先 Distance(d1/r2/n0,d1/r3/n0)=4
三、机架感知 Link to heading 机架感知是一种计算不同计算节点（TaskTracker）的距离的技术，用以在任务调度过程中尽量减少网络带宽资源的消耗，这里用尽量，想表达的是当一个 TT（TaskTracker）申请不到本地化任务时，JT（JobTracker）会尽量调度一个机架的任务给他，因为不同机架的网络带宽资源比同一个机架的网络带宽资源更可贵。
第一个副本选择在 client 所处的节点上，如果客户端在集群外随机选一个
第二个副本在另一个机架的随机节点上 第三个在第二个副本所在的机架的随机节点上</description></item></channel></rss>