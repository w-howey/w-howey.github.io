<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>Hadoop on YanHowey Wang</title><link>https://howey.deno.dev/tags/hadoop/</link><description>Recent content in Hadoop on YanHowey Wang</description><generator>Hugo</generator><language>en</language><lastBuildDate>Wed, 26 Jul 2023 22:21:16 +0800</lastBuildDate><atom:link href="https://howey.deno.dev/tags/hadoop/index.xml" rel="self" type="application/rss+xml"/><item><title>hadoop集群搭建（二）之集群配置</title><link>https://howey.deno.dev/posts/2307262205/</link><pubDate>Wed, 26 Jul 2023 22:21:16 +0800</pubDate><guid>https://howey.deno.dev/posts/2307262205/</guid><description>hadoop 集群搭建（二）之集群配置 Link to heading @TOC
一、集群部署规划 Link to heading 1.NameNode 和 SecoundNameNode 不要安装在同一台服务器 2.ResourceManager 也很消耗内存，不要和 NameNode、SecoundNameNode 配置在同一台机器上
hadoop102 hadoop103 hadoop104 HDFS NameNode DataNode DataNode SecoundNameNode DataNode yarn NodeManager ResourceManager NodeManager NodeManager 二、修改配置文件 Link to heading 1. /opt/module/hadoop-3.3.1/etc/hadoop/core-site.xml Link to heading &amp;lt;configuration&amp;gt; &amp;lt;!--指定nodename地址 --&amp;gt; &amp;lt;property&amp;gt; &amp;lt;name&amp;gt;fs.defaultFS&amp;lt;/name&amp;gt; &amp;lt;value&amp;gt;hdfs://hadoop102:8020&amp;lt;/value&amp;gt; &amp;lt;/property&amp;gt; &amp;lt;!-- ָ指定hadoop数据的存储目录 --&amp;gt; &amp;lt;property&amp;gt; &amp;lt;name&amp;gt;hadoop.tmp.dir&amp;lt;/name&amp;gt; &amp;lt;value&amp;gt;/opt/module/hadoop-3.3.1/data&amp;lt;/value&amp;gt; &amp;lt;/property&amp;gt; &amp;lt;!-- 配置hsfs网页登录使用的静态用户--&amp;gt; &amp;lt;!-- &amp;lt;property&amp;gt; --&amp;gt; &amp;lt;!-- &amp;lt;name&amp;gt;hadoop.http.staticuser.user&amp;lt;/name&amp;gt; --&amp;gt; &amp;lt;!-- &amp;lt;value&amp;gt;howey&amp;lt;/value&amp;gt; --&amp;gt; &amp;lt;!-- &amp;lt;/property&amp;gt; --&amp;gt; &amp;lt;/configuration&amp;gt; 2.</description></item><item><title>HDFS介绍以及shell操作</title><link>https://howey.deno.dev/posts/2307262208/</link><pubDate>Wed, 26 Jul 2023 22:21:16 +0800</pubDate><guid>https://howey.deno.dev/posts/2307262208/</guid><description>HDFS Link to heading @[TOC]
一、HDFS 定义 Link to heading HDFS 即（hadoop distributed file system），采用目录树来定位文件；其次，它是分布式的，由很多服务器联合起来实现其功能，集群中的服务器有各自的角色 HDFS 的使用场景：适合一次写入，多次读出的场景
二、HDFS 优缺点： Link to heading 1.优点： Link to heading 高容错性 数据自动保存多个副本。通过增加副本的形式，提高容错性 某一个副本丢失以后，可以自动回复 适合处理大数据 数据规模大的（甚至 PB），文件规模大的（上百万） 可以构建在廉价机器上，通过多副本机制，提高可靠性 2.缺点： Link to heading 不适合低延时数据访问，比如毫秒级存储 无法高效的对大量小文件进行存储（1.存储大量小文件，会占用 nameNode 大量的内存用来存储文件目录和块消息，namenode 内存总是有限的 2.小文件存储的寻址时间会超过读取时间，违反了 hdfs 的设计目的） 不支持并发写入，文件的随机修改，（1.一个文件只能有一个写，不允许多个线程同时写 2.仅支持数据的追加，不支持修改） 三、HDFS 组织架构 Link to heading client: 分别访问 NameNode 和 DataNode 以获取文件的元信息及内容。
SecondaryNamenode：辅助 namenode 用于定期合并 fsimage 和 edits，生成新的 fsimage，并推送给 Namenode，在紧急情况下 可用于恢复 namenode 部分数据</description></item><item><title>HDFS常用API操作</title><link>https://howey.deno.dev/posts/2307262206/</link><pubDate>Wed, 26 Jul 2023 22:21:16 +0800</pubDate><guid>https://howey.deno.dev/posts/2307262206/</guid><description>1.下载 winutils.exe Link to heading https://codeload.github.com/tangchunbo/apache-hadoop-3.1.1-winutils/zip/refs/heads/master 然后解压将文件拷贝到 bin 目录下 D:\Java\hadoop-3.3.1\bin 依赖导入
&amp;lt;dependencies&amp;gt; &amp;lt;dependency&amp;gt; &amp;lt;groupId&amp;gt;org.apache.hadoop&amp;lt;/groupId&amp;gt; &amp;lt;artifactId&amp;gt;hadoop-client&amp;lt;/artifactId&amp;gt; &amp;lt;version&amp;gt;3.1.3&amp;lt;/version&amp;gt; &amp;lt;/dependency&amp;gt; &amp;lt;dependency&amp;gt; &amp;lt;groupId&amp;gt;junit&amp;lt;/groupId&amp;gt; &amp;lt;artifactId&amp;gt;junit&amp;lt;/artifactId&amp;gt; &amp;lt;version&amp;gt;4.12&amp;lt;/version&amp;gt; &amp;lt;/dependency&amp;gt; &amp;lt;dependency&amp;gt; &amp;lt;groupId&amp;gt;org.slf4j&amp;lt;/groupId&amp;gt; &amp;lt;artifactId&amp;gt;slf4j-log4j12&amp;lt;/artifactId&amp;gt; &amp;lt;version&amp;gt;1.7.30&amp;lt;/version&amp;gt; &amp;lt;/dependency&amp;gt; &amp;lt;/dependencies&amp;gt; package com.howey.hdfs; import org.apache.hadoop.conf.Configuration; import org.apache.hadoop.fs.*; import org.junit.After; import org.junit.Before; import org.junit.Test; import java.io.IOException; import java.net.URI; import java.net.URISyntaxException; import java.util.Arrays; /** * 1.获取客户端对象 * 2.执行相关的操作命令 * 3.关闭资源 */ public class HdfsClient { private FileSystem fs; @Before public void init() throws URISyntaxException, IOException, InterruptedException { URI uri = new URI(&amp;#34;hdfs://hadoop102:8020&amp;#34;); //创建一个配置文件 Configuration entries = new Configuration(); //设置副本 entries.</description></item><item><title>HDFS读写数据流程</title><link>https://howey.deno.dev/posts/2307262207/</link><pubDate>Wed, 26 Jul 2023 22:21:16 +0800</pubDate><guid>https://howey.deno.dev/posts/2307262207/</guid><description>HDFS 读写数据流程 Link to heading @[TOC]
一、HDFS 写数据流程 Link to heading 客户端发起请求上传文件 namenode 检查目录树是否可以创建文件（1.检查权限，2 检查目录树结构，目录是否存在）并响应客户端是否可上传 客户端对文件进行分操作形成 block 块 请求上传第一个 block，请求返回 datanode（上传的数据真实存储的地址） 根据机架感应原理，网络拓扑关系，副本机制，找到相应可以上传的 datanode 连接列表，返回给客户端。 根据返回的连接列表 客户端请求与第一台机器建立 block 传输通道 datanode 连接列表一次进行连接形成一条完整的 pipeline 管道 客户端，将第一个数据包 packet（64k 由（chunk512b+chunksum4b）组成）发送数据，然后依次由服务器进行管道传输，服务器会自我保存一份 第一个请求完成之后，建立一条反向应答通道，ack 应答机制 10.第一个请求完成之后，开始继续发送 packet，当第一个 block 发送完成后，此时 client 重新向 namenode 发送请求，获取第二个 block 应该存储到哪个 datanode 中，接着开始从第 5 步不断执行，直到所有的 block 完全写入。 二、节点距离计算 Link to heading 到达共同祖先 Distance(d1/r2/n0,d1/r3/n0)=4
三、机架感知 Link to heading 机架感知是一种计算不同计算节点（TaskTracker）的距离的技术，用以在任务调度过程中尽量减少网络带宽资源的消耗，这里用尽量，想表达的是当一个 TT（TaskTracker）申请不到本地化任务时，JT（JobTracker）会尽量调度一个机架的任务给他，因为不同机架的网络带宽资源比同一个机架的网络带宽资源更可贵。
第一个副本选择在 client 所处的节点上，如果客户端在集群外随机选一个
第二个副本在另一个机架的随机节点上 第三个在第二个副本所在的机架的随机节点上</description></item><item><title>hodoop集群搭建之分发脚本以及ssh免密登录</title><link>https://howey.deno.dev/posts/2307262209/</link><pubDate>Wed, 26 Jul 2023 22:21:16 +0800</pubDate><guid>https://howey.deno.dev/posts/2307262209/</guid><description>hodoop 介绍 Link to heading @TOC
一、hadoop 三种运行模式 Link to heading 本地模式 ：数据存储在 linux 本地（只是在测试偶尔用） 伪分布式：数据存储在 HDFS（一台主机模拟多主机） 完全分布式：数据存储在 HDFS（多台服务器工作）企业大量使用
二、模式示例 Link to heading 1.本地模式 Link to heading 在 hadoop 文件夹下新建
mkdir wcinput cd wcinput vim word.txt //任意写入内容 ./wcoutput 要是不存在的文件夹，不然会抛出异常
hadoop jar share/hadoop/mapreduce/hadoop-mapreduce-examples-3.3.1.jar wordcount wcinput/ ./wcoutput cat part-r-00000 2.完全分布式模式 Link to heading （1）流程 Link to heading 准备 3 台客户机（关闭防火墙，静态 ip，主机名称） List item 安装 jdk，hadoop 配置环境变量 配置集群 单点启动 配置 ssh 群起测试集群 （2）编写集群分发脚本 xsync Link to heading 1.</description></item><item><title>虚拟机搭建 hadoop</title><link>https://howey.deno.dev/posts/2307262201/</link><pubDate>Wed, 26 Jul 2023 22:21:16 +0800</pubDate><guid>https://howey.deno.dev/posts/2307262201/</guid><description>虚拟机搭建 hadoop Link to heading @TOC
一、搭建 centos 虚拟机， Link to heading 1.分区等设置 Link to heading 下载镜像导入 ，分区： 硬件：内存 2G，硬盘 50G 分区：/boot 挂载 1g /swap 挂载 4G （内存不够可采用磁盘当内存使用） /挂载 45G
2.网络 ip 设置 Link to heading （1）虚拟网络编辑器设置：选择 vmnet8 子网 ip 设置网段修改为任意网段 例如 10 nat 设置：原则同网段就想 （2）本地机设置：vmnet8 ipv4 属性 （3）虚拟机 centos 系统设置：
vim /etc/sysconfig/network-scripts/ifcfg-ens33 如下： 最后重启一下虚拟机。。 ping 一下外网和内网，查看是否能通信，通信就搞定 设置一下 host vim /etc/hosts 安装一下软件工具包 yum install -y epel-release 关闭防火墙 systemctl stop firewalld 禁止防火墙开机自启 systemctl disable firewalld.</description></item></channel></rss>